{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TPU U-Net Cup Disc Segmentation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/javicivit/TPU-UNET/blob/master/TPU_U_Net_Cup_Disc_Segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "uRU_Go8J4cK4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Train with RIM one and DRISHTI\n",
        "## TPU based UNET Segmentation.\n",
        "\n",
        "The colaboratory demostrates  the segmentation of Fundus images using the very well known U-Net network in Keras.\n",
        "This work is originally based on:\n",
        "[Sevastopolsky A., Optic disc and cup segmentation methods for glaucoma detection with modification of U-Net convolutional neural network, Pattern Recognition and Image Analysis 27 (2017), no. 3, 618–624](https://github.com/seva100/optic-nerve-cnn )\n",
        "\n",
        "The code was rewriten and adapted to TPU based trainning by Javier Civit and Anton Civit. The main modifications are:\n",
        "* We use a completely different dual image generator and use it for both training and testing. For TPU training we need much larger static datasets and, thus we also make use of static data augmentation including images with modified brightness and modified parameters for the adaptive histogram equalization. This, together with the use of images from three different publicly available datasets for training and validation improves the robustness to the use if images acquired with different instruments.\n",
        "* We use the version of Keras included in tensorflow. This is necessary to be able to execute in TPUs.\n",
        "* We use [Pröve's parameterizable recursive U-net model](https://github.com/pietz/unet-keras). This model allows us to easily change many parameters necessary to compare different implementations of U-Net. Specifically, we can change the network depth and with, the use of drop out and batch normalization, the use of upsampling (although this type of layer is not currently supported by Keras in TPUs) nor transpose convolution and the width ratio between successive layers\n",
        "* We use 120 image batches for both training and testing and train for 15 epochs using 150 training steps and 30 testing steps per epoch. We use an Adam optimizer algorithm in most cases with a .00075 learning rate although in a few cases, we have had to lower this value to ensure convergence. This values have proven suitable for TPU based training in U-Net architecture and provide good results with training times bellow 20 minutes even in the most complex implementations.\n",
        "* Training is completely rewritten to run on TPUs\n",
        "* The radii ratio parameter is calculated.\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Azl8XMZXwst5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Training of a modified U-Net for Optic Disc/Cup on RIM-ONE v3  & DRISHTI databases.\n",
        "\n",
        "We use publicly available RIM-ONE v3, DRISHTI and DRIONS datasets. The use of multiple datasets both for training and for validation allows our system to be more independent of the capture devices than other available implementations. RIM ONE-v3, from the MIAG group of the University of La Laguna (Spain), consists of 159 fundus images which have been labeled by expert ophthalmologists for both disc and cup. DRISHTI-GS, from Aravind Eye hospital, Madurai, India consists of 101 fundus images also labeled for disc and cup. DRIONS-DB from Miguel Servet Hospital, Saragossa (Spain), consists of 110 images on which only the optic cup has been labelled.\n",
        "Fundus images and disk maskks are resized in one sted to 128x128.  The hdf versions of the Datasets can be uploaded from [Sevastopolsky's github](https://github.com/seva100/optic-nerve-cnn). [Datasets](https://drive.google.com/drive/folders/13g62bhqN1JHJ2fky2Xy5avLbZ2YLMdwB?usp=sharing)\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "WzA-sEscHNZO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Lets load the data from Gdrive\n",
        "We will use the colab interface to google drive. See: https://colab.research.google.com/notebooks/io.ipynb \n"
      ]
    },
    {
      "metadata": {
        "id": "FsKfQRodfdzg",
        "colab_type": "code",
        "outputId": "20e207cf-3c20-45c8-b73a-30979bdd7783",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NNYvLW7T8dk1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Colab drive only allows file open, read and write thus we define our own copy function:"
      ]
    },
    {
      "metadata": {
        "id": "3Gk4-lNiJLTw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def copy( fs,fd):\n",
        "  f1=open(fs,'rb')\n",
        "  \n",
        "  fs_c=f1.read()\n",
        "  f2=open(fd,'w+b')\n",
        "  f2.write(fs_c)\n",
        "  f1.close()\n",
        "  \n",
        "  \n",
        "  f2.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4v481bPRqJTA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Copy the Dataset from Gdrive to the colab machine HD"
      ]
    },
    {
      "metadata": {
        "id": "unTy6FaXlnZ2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "copy('/content/gdrive/My Drive/RIM_ONE_v3.hdf5','/content/RIM_ONE_v3.hdf5')\n",
        "copy('/content/gdrive/My Drive/DRIONS_DB.hdf5','/content/DRIONS_DB.hdf5')\n",
        "copy('/content/gdrive/My Drive/DRISHTI_GS.hdf5','/content/DRISHTI_GS.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RDyFVtSMqZ3P",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Check copy"
      ]
    },
    {
      "metadata": {
        "id": "Zg7ETt04WZcO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls -l  '/content'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eNNJyABSdEwN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's import the required libraries:"
      ]
    },
    {
      "metadata": {
        "id": "_xV9Nn6JwIkR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "import os\n",
        "import glob\n",
        "from datetime import datetime\n",
        "#import warnings\n",
        "#warnings.simplefilter('ignore')\n",
        "import scipy as sp\n",
        "import scipy.ndimage\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import skimage\n",
        "import skimage.exposure\n",
        "import skimage.transform\n",
        "import skimage.measure\n",
        "#from sklearn.cross_validation import KFold\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import cv2\n",
        "import h5py\n",
        "from tqdm import tqdm_notebook\n",
        "#import mahotas as mh\n",
        "from IPython.display import display\n",
        "#from dual_IDG import DualImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras import layers as layers\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, \\\n",
        "    Conv2D, MaxPooling2D, ZeroPadding2D, Input, Embedding, LSTM,  \\\n",
        "    Lambda, UpSampling2D,concatenate,Conv2DTranspose\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.optimizers import SGD, Adam, Adagrad\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau, CSVLogger\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import backend as K\n",
        "from sklearn.model_selection import train_test_split\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KFEukCj8qkZI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Set the adequate floating point format. 32bit precission is enough."
      ]
    },
    {
      "metadata": {
        "id": "cDBXuIPfxs3X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "K.set_floatx('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rur-I-N28wx3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Our loss function is based on dice (intersectionover union).\n",
        "We use -log(dice) as our loss function as this seems to work better but, of course you can play with it.\n",
        "This is based on: https://github.com/EdwardTyantov/ultrasound-nerve-segmentation "
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "L3gKgtXdwsuO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + K.epsilon()) / (K.sum(y_true_f) + K.sum(y_pred_f) + K.epsilon())\n",
        "  \n",
        "def dice_loss(y_true,y_pred):\n",
        "    return -dice_coef(y_true,y_pred)\n",
        "  \n",
        "def log_dice_loss(y_true, y_pred):\n",
        "    return -K.log(dice_coef(y_true, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gg0qqjkBdgST",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Auxiliary function to modify image brightness."
      ]
    },
    {
      "metadata": {
        "id": "79Jic7wYc6mk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def modify_brightness_p(img, p=1.2):\n",
        "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "    h, s, v = cv2.split(hsv)\n",
        "\n",
        "    lim = 1.0/p\n",
        "    v[v > lim] = 1.0\n",
        "    v[v <= lim] *= p\n",
        "    #print(np.amax(v))\n",
        "\n",
        "    final_hsv = cv2.merge((h, s, v))\n",
        "    img = cv2.cvtColor(final_hsv, cv2.COLOR_HSV2BGR).clip(min=0)\n",
        "    return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9H3lx-WRdoN1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Auxiliary funtion to shuffle to vectors in a coherent way:"
      ]
    },
    {
      "metadata": {
        "id": "82FWBt7h9dGP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def unison_shuffled_copies(a, b):\n",
        "    assert len(a) == len(b)\n",
        "    p = np.random.permutation(len(a))\n",
        "    return a[p], b[p]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3EzC1skrdxpa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Auxiliary function to use 512 image size indexes with original images."
      ]
    },
    {
      "metadata": {
        "id": "NFChKFpTU6I0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def index512_resize(index,top):\n",
        "  index=index*top/512\n",
        "  return int(index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MG9xchH7AOxM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Our data is in hdf5 (https://www.h5py.org/) format. \n",
        "We will use it Train/test with  Drishti and RimONE"
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "w7wU3WR3wsuZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#h5f1 = h5py.File(os.path.join(os.path.dirname(os.getcwd()), 'content', 'all_data.hd5f'), 'r')\n",
        "h5f1 = h5py.File(os.path.join(os.path.dirname(os.getcwd()), 'content', 'RIM_ONE_v3.hdf5'), 'r')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AZniiBsXV3pP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "h5f2=h5py.File(os.path.join(os.path.dirname(os.getcwd()), 'content', 'DRISHTI_GS.hdf5'), 'r')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Sgu3qDaW7XZC",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "h5v1=h5py.File(os.path.join(os.path.dirname(os.getcwd()), 'content', 'DRIONS_DB.hdf5'), 'r')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yKL8-3-iwsuc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### U-Net architecture\n",
        "\n",
        "We use a version of the net presented in: https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/ \n",
        "The generalized U-Net is based on https://github.com/pietz/unet-keras"
      ]
    },
    {
      "metadata": {
        "id": "82nCHO8WiREs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "U-Net: Convolutional Networks for Biomedical Image Segmentation\n",
        "(https://arxiv.org/abs/1505.04597)\n",
        "---\n",
        "img_shape: (height, width, channels)\n",
        "out_ch: number of output channels\n",
        "start_ch: number of channels of the first conv\n",
        "depth: zero indexed depth of the U-structure\n",
        "inc_rate: rate at which the conv channels will increase\n",
        "activation: activation function after convolutions\n",
        "dropout: amount of dropout in the contracting part\n",
        "batchnorm: adds Batch Normalization if true\n",
        "maxpool: use strided conv instead of maxpooling if false\n",
        "upconv: use transposed conv instead of upsamping + conv if false\n",
        "residual: add residual connections around each conv block if true\n",
        "'''\n",
        "\n",
        "def conv_block(m, dim, acti, bn, res, do=0):\n",
        "\tn = Conv2D(dim, 3, activation=acti, padding='same')(m)\n",
        "\tn = BatchNormalization()(n) if bn else n\n",
        "\tn = Dropout(do)(n) if do else n\n",
        "\tn = Conv2D(dim, 3, activation=acti, padding='same')(n)\n",
        "\tn = BatchNormalization()(n) if bn else n\n",
        "\treturn Concatenate()([m, n]) if res else n\n",
        "\n",
        "def level_block(m, dim, depth, inc, acti, do, bn, mp, up, res):\n",
        "\tif depth > 0:\n",
        "\t\tn = conv_block(m, dim, acti, bn, res)\n",
        "\t\tm = MaxPooling2D()(n) if mp else Conv2D(dim, 3, strides=2, padding='same')(n)\n",
        "\t\tm = level_block(m, int(inc*dim), depth-1, inc, acti, do, bn, mp, up, res)\n",
        "\t\tif up:\n",
        "\t\t\tm = UpSampling2D()(m)\n",
        "\t\t\tm = Conv2D(dim, 2, activation=acti, padding='same')(m)\n",
        "\t\telse:\n",
        "\t\t\tm = Conv2DTranspose(dim, 3, strides=2, activation=acti, padding='same')(m)\n",
        "\t\tn = concatenate([n, m],axis=-1)\n",
        "\t\tm = conv_block(n, dim, acti, bn, res)\n",
        "\telse:\n",
        "\t\tm = conv_block(m, dim, acti, bn, res, do)\n",
        "\treturn m\n",
        "\n",
        "def UNet(img_shape, out_ch=1, start_ch=64, depth=4, inc_rate=2., activation='relu', \n",
        "\t\t dropout=0.5, batchnorm=False, maxpool=True, upconv=True, residual=False):\n",
        "\ti = Input(shape=img_shape)\n",
        "\to = level_block(i, start_ch, depth, inc_rate, activation, dropout, batchnorm, maxpool, upconv, residual)\n",
        "\to = Conv2D(out_ch, 1, activation='sigmoid')(o)\n",
        "\treturn Model(inputs=i, outputs=o)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HysxXobUmqE8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Change these parameters according to  the architecture . Uss Cup=True to segment the Cup and False to segment the disk."
      ]
    },
    {
      "metadata": {
        "id": "BVAiDcVW-7-K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img_shape=(128,128,3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L-zvdIlY_JDm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cup=True\n",
        "name='CUPa05d5w64ir16bn'\n",
        "model=UNet(img_shape,start_ch=64,upconv=False,dropout=0.65, depth=5,inc_rate=1.6, batchnorm=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7TrylbLR-hFX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Lets visualize the model and save its graphical representation."
      ]
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "nkfWtuJ1wsum",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d1vXPLpQoYLz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Plot model graph\n",
        "plot_model(model, show_shapes=True, show_layer_names=True, to_file='model.png')\n",
        "from IPython.display import Image\n",
        "Image(retina=True, filename='model.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yXKNp_ADrHOI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "copy ('/content/model.png','/content/gdrive/My Drive/model_CE5an.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "Izvq0gnjwsvW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "arch_name='TPU'\n",
        "weights_folder = os.path.join(os.path.dirname(os.getcwd()), 'models_weights', arch_name))\n",
        "\n",
        "def folder(folder_name):\n",
        "    if not os.path.exists(folder_name):\n",
        "        os.makedirs(folder_name)\n",
        "    return folder_name\n",
        "  \n",
        "weights_folder\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bq6QRrAFCfX0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**DRISHTI RIM ONE CUP Aggressive augmentation**\n",
        "\n",
        "Accessing data, preparing train/validation sets: Resize & Prepare"
      ]
    },
    {
      "metadata": {
        "id": "R_4GQ6QZC4_E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Xori= h5f2['DRISHTI-GS/orig/images']\n",
        "disc_locations = h5f2['DRISHTI-GS/512 px/disc_locations']\n",
        "isize=Xori.shape[1]\n",
        "\n",
        "if(cup):\n",
        "  Yf = h5f2['DRISHTI-GS/512 px/cup']\n",
        "  Xc = [Xori[i][index512_resize(disc_locations[i][0],isize):index512_resize(disc_locations[i][2],isize), index512_resize(disc_locations[i][1],isize):index512_resize(disc_locations[i][3],isize)] \n",
        "                   for i in range(len(Xori))]\n",
        "\n",
        "  Yc=[Yf[i][disc_locations[i][0]:disc_locations[i][2], disc_locations[i][1]:disc_locations[i][3]] \n",
        "                   for i in range(len(Xori))]\n",
        "else:\n",
        "  Yf = h5f2['DRISHTI-GS/512 px/disc']\n",
        "  Xc = [Xori[i][index512_resize(50,isize):index512_resize(462,isize), index512_resize(50,isize):index512_resize(462,isize)] \n",
        "                   for i in range(len(Xori))]\n",
        "\n",
        "  Yc=[Yf[i][50:462,50:462] \n",
        "                   for i in range(len(Xori))]\n",
        "\n",
        "Xa=[cv2.resize(img, (128, 128),interpolation=cv2.INTER_NEAREST) for img in Xc]\n",
        "X=[skimage.exposure.equalize_adapthist(img, clip_limit=0.035)  for img in Xa]\n",
        "X=np.asarray(X) \n",
        "am=np.amax(X)\n",
        "X=X.astype(np.float32)/am \n",
        "print(np.amax(X),np.amin(X))\n",
        "\n",
        "Y=[cv2.resize(img, (128, 128),interpolation=cv2.INTER_NEAREST)[..., None] for img in Yc]\n",
        "Y=np.asarray(Y) \n",
        "ym=np.amax(Y) \n",
        "Yf=Y/ym \n",
        "Yb=(Y>0.5).astype(np.float32) #get binary mask\n",
        "\n",
        "\n",
        "print(np.amax(Yf),np.amin(Yf))\n",
        "print(X.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2e0cSAtE7dpI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Xvori= h5f1['RIM-ONE v3/orig/images']\n",
        "disc_locationsv = h5f1['RIM-ONE v3/512 px/disc_locations']\n",
        "ivsize=Xvori.shape[1]\n",
        "if (cup):\n",
        "  Yvf = h5f1['RIM-ONE v3/512 px/cup']\n",
        "  Xvc = [Xvori[i][index512_resize(disc_locationsv[i][0],ivsize):index512_resize(disc_locationsv[i][2],ivsize), index512_resize(disc_locationsv[i][1],ivsize):index512_resize(disc_locationsv[i][3],ivsize)] \n",
        "                     for i in range(len(Xvori))]\n",
        "\n",
        "  Yvc=[Yvf[i][disc_locationsv[i][0]:disc_locationsv[i][2], disc_locationsv[i][1]:disc_locationsv[i][3]] \n",
        "                     for i in range(len(Xvori))]\n",
        "\n",
        "else:\n",
        "  Yvf = h5f1['RIM-ONE v3/512 px/disc']\n",
        "  Xvc = [Xvori[i][index512_resize(50,isize):index512_resize(462,ivsize), index512_resize(50,isize):index512_resize(462,ivsize)] \n",
        "                     for i in range(len(Xvori))]\n",
        "\n",
        "  Yvc=[Yvf[i][50:462,50:462] \n",
        "                     for i in range(len(Xvori))]\n",
        "\n",
        "\n",
        "Xvn=[cv2.resize(img, (128, 128),interpolation=cv2.INTER_NEAREST) for img in Xvc]\n",
        "Xv=[skimage.exposure.equalize_adapthist(img, clip_limit=0.035)  for img in Xvn]\n",
        "\n",
        "Xv=np.asarray(Xv) \n",
        "am=np.amax(Xv)\n",
        "Xv=Xv.astype(np.float32)/am \n",
        "print(np.amax(Xv),np.amin(Xv))\n",
        "\n",
        "Yv=[cv2.resize(img, (128, 128),interpolation=cv2.INTER_NEAREST)[..., None] for img in Yvc]\n",
        "\n",
        "Yv=np.asarray(Yv) \n",
        "ym=np.amax(Yv) \n",
        "Yvf=(Yv/ym).astype(np.float32) \n",
        "print(np.amax(Yvf),np.amin(Yvf))\n",
        "print(Xv.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zHNaYlp3C_qI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " Distibute between train & test.\n",
        " Create more \"data\". Just copy the vectors over themselves and add modified versions so that the generators can  produce longer batches "
      ]
    },
    {
      "metadata": {
        "id": "bOkf5DyYMIVl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "rng = np.random.RandomState(42)\n",
        "#X=np.concatenate([X,Xv])\n",
        "#Yf=np.concatenate([Yf,Yvf])\n",
        "  \n",
        "X_train1t, X_test1t, Y_train1t, Y_test1t = train_test_split( X, Yb, test_size=0.25,random_state=rng)\n",
        "X_train2, X_test2, Y_train2, Y_test2 = train_test_split( Xv, Yvf, test_size=0.25,random_state=rng)\n",
        "\n",
        "X_train1=np.concatenate([X_train1t,X_train1t])\n",
        "X_train1=np.concatenate([X_train1,X_train1t])\n",
        "X_test1=np.concatenate([X_test1t,X_test1t])\n",
        "X_train1=np.concatenate([X_test1,X_test1t])\n",
        "\n",
        "Y_train1=np.concatenate([Y_train1t,Y_train1t])\n",
        "Y_train1=np.concatenate([Y_train1,Y_train1t])\n",
        "Y_test1=np.concatenate([Y_test1t,Y_test1t])\n",
        "Y_train1=np.concatenate([Y_test1,Y_test1t])\n",
        "\n",
        "X_train1=np.concatenate([X_train1,X_train2])\n",
        "Y_train1=np.concatenate([Y_train1,Y_train2])\n",
        "X_test=np.concatenate([X_test1,X_test2])\n",
        "Y_test=np.concatenate([Y_test1,Y_test2])\n",
        "\n",
        "X_train1=np.asarray(X_train1)\n",
        "Y_train1=np.asarray(Y_train1)\n",
        "X_test=np.asarray(X_test)\n",
        "Y_test=np.asarray(Y_test)\n",
        "\n",
        "X_train=np.copy(X_train1)\n",
        "Y_train=np.copy(Y_train1)\n",
        "\n",
        "size=X_train1.shape[0]\n",
        "\n",
        "X_traine=np.empty((3160, 128, 128, 3),dtype=np.float32)\n",
        "Y_traine=np.empty((3160, 128, 128, 1),dtype=np.float32)\n",
        "\n",
        "\n",
        "\n",
        "for i in range(16):\n",
        "  #print(i*size,(i+1)*size)\n",
        "  X_traine[i*size:(i+1)*size]=X_train1\n",
        "  Y_traine[i*size:(i+1)*size]=Y_train1\n",
        "  \n",
        "base= 16*size\n",
        "\n",
        "for j in tqdm_notebook(range(X_train1.shape[0])):\n",
        "  X_traine[base]=skimage.exposure.equalize_adapthist(X_train1[j], clip_limit=0.4)\n",
        "  Y_traine[base]=Y_train1[j]\n",
        "  base+=1\n",
        "  X_traine[base]=skimage.exposure.equalize_adapthist(X_train1[j], clip_limit=0.2)\n",
        "  Y_traine[base]=Y_train1[j]\n",
        "  base+=1\n",
        "  X_traine[base]=modify_brightness_p(X_train1[j],0.9)\n",
        "  Y_traine[base]=Y_train1[j]\n",
        "  base+=1\n",
        "  X_traine[base]=modify_brightness_p(X_train1[j],1.1)\n",
        "  Y_traine[base]=Y_train1[j]\n",
        "  base+=1\n",
        "  \n",
        "X_testc=np.copy(X_test)\n",
        "Y_testc=np.copy(Y_test)\n",
        "\n",
        "sizev=X_testc.shape[0]\n",
        "\n",
        "X_teste=np.empty((792, 128, 128, 3),dtype=np.float32)\n",
        "Y_teste=np.empty((792, 128, 128, 1),dtype=np.float32)\n",
        "\n",
        "for i in range(8):\n",
        "  X_teste[i*sizev:(i+1)*sizev]=X_testc\n",
        "  Y_teste[i*sizev:(i+1)*sizev]=Y_testc\n",
        "  \n",
        "basev= 8*sizev\n",
        "\n",
        "for j in tqdm_notebook(range(X_testc.shape[0])):\n",
        "  X_teste[basev]=skimage.exposure.equalize_adapthist(X_testc[j], clip_limit=0.4)\n",
        "  Y_teste[basev]=Y_testc[j]\n",
        "  basev+=1\n",
        "  X_teste[basev]=skimage.exposure.equalize_adapthist(X_testc[j], clip_limit=0.2)\n",
        "  Y_teste[basev]=Y_testc[j]\n",
        "  basev+=1\n",
        "  X_teste[basev]=modify_brightness_p(X_testc[j],0.9)\n",
        "  Y_teste[basev]=Y_testc[j]\n",
        "  basev+=1\n",
        "  X_teste[basev]=modify_brightness_p(X_testc[j],1.1)\n",
        "  Y_teste[basev]=Y_testc[j]\n",
        "  basev+=1\n",
        "  \n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6BveoOA6E0is",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(X_traine.shape,Y_traine.shape,X_teste.shape,Y_teste.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rjtXdPruE9vi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***Aumented dual image generator***\n",
        "Based on the example at:\n",
        "https://keras.io/preprocessing/image/#imagedatagenerator-class \n",
        "Had to modified as zipped version is currently not accepted"
      ]
    },
    {
      "metadata": {
        "id": "ApTY7GiMrSFj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Start by shuffling the data:"
      ]
    },
    {
      "metadata": {
        "id": "k0LN9Tqi-BWg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_trains,Y_trains=unison_shuffled_copies(X_traine, Y_traine)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gKMaSRPwVoH-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_tests,Y_tests=unison_shuffled_copies(X_teste, Y_teste)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XAMuOnUGFI4o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Provide the same seed and keyword arguments to the fit and flow methods\n",
        "seed=42\n",
        "batch_s=120\n",
        "#batch_s=96 #conv_Trans will not run in GPU with 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "73WMjwbyFLjH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_gen_args = dict(#rescale=1./255,\n",
        "                     #featurewise_center=True,\n",
        "                     #featurewise_std_normalization=True,\n",
        "                     horizontal_flip=True, vertical_flip=True,\n",
        "                     rotation_range=30,\n",
        "                     width_shift_range=0.1,\n",
        "                     height_shift_range=0.1,\n",
        "                     zoom_range=0.2,\n",
        "                     fill_mode='constant', cval=0.0, \n",
        "                     #brightness_range=[-0.1,0.1],\n",
        "                     #preprocessing_function=skimage.exposure.equalize_adapthist,\n",
        "                     dtype='float32'\n",
        "                     )\n",
        "image_datagen = ImageDataGenerator(**data_gen_args)\n",
        "mask_datagen = ImageDataGenerator(**data_gen_args)\n",
        "\n",
        "image_generator = image_datagen.flow(\n",
        "    X_trains,\n",
        "    batch_size=batch_s,\n",
        "    seed=seed)\n",
        "\n",
        "mask_generator = mask_datagen.flow(\n",
        "    Y_trains,\n",
        "    batch_size=batch_s,\n",
        "    seed=seed)\n",
        "\n",
        "#train_generator = zip(image_generator, mask_generator)\n",
        "def train_generator():\n",
        "  while True:\n",
        "    yield image_generator.next(),mask_generator.next()\n",
        "    \n",
        "\n",
        "image_generator_test = image_datagen.flow(\n",
        "    X_tests,\n",
        "    batch_size=batch_s,\n",
        "    seed=seed)\n",
        "\n",
        "mask_generator_test = mask_datagen.flow(\n",
        "    Y_tests,\n",
        "    batch_size=batch_s,\n",
        "    seed=seed)\n",
        "\n",
        "#test_generator = zip(image_generator_test, mask_generator_test)\n",
        "def test_generator():\n",
        "  while True:\n",
        "    yield image_generator_test.next(),mask_generator_test.next()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GedrFNQHFhP7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Set the place for localy saving the weights. After training we will copy to Gdrive"
      ]
    },
    {
      "metadata": {
        "id": "tdJiHcVxFj1S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "weights_folder = os.path.join(os.path.dirname(os.getcwd()), 'models_weights')\n",
        "\n",
        "def folder(folder_name):\n",
        "    if not os.path.exists(folder_name):\n",
        "        os.makedirs(folder_name)\n",
        "    return folder_name\n",
        "  \n",
        "weights_folder\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "62etdByjLvlb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Train on TPU (DO not exec on GPU)"
      ]
    },
    {
      "metadata": {
        "id": "NjeXnxFZMDq3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#This address identifies the TPU we'll use when configuring TensorFlow.\n",
        "TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mo3SyTsIrvv2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Convert model to TPU format"
      ]
    },
    {
      "metadata": {
        "id": "9RJq8093MKQf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tpu_model = tf.contrib.tpu.keras_to_tpu_model(\n",
        "    model,\n",
        "    strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "        tf.contrib.cluster_resolver.TPUClusterResolver(tpu=TPU_WORKER),\n",
        "        using_single_core=False\n",
        "    )\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Un_xTzdd-pPx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Compile TPU model. We are using the Tensorflow version of the Adan optimizer https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/ ."
      ]
    },
    {
      "metadata": {
        "id": "JtuIAmRPMK8O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tpu_model.compile(\n",
        "    #optimizer=tf.train.AdagradOptimizer(learning_rate=0.05 ),\n",
        "    #loss = 'binary_crossentropy', metrics = ['accuracy']\n",
        "    #optimizer=SGD(lr=3e-4, momentum=0.95), \n",
        "    #optimizer=tf.train.Adagrad(),\n",
        "    optimizer=tf.train.AdamOptimizer(learning_rate=0.00075 ),\n",
        "    loss=log_dice_loss, metrics=[dice_coef]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GtZZ7qbgsRqs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now let's Train the model."
      ]
    },
    {
      "metadata": {
        "id": "dBxpc305MP_w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%time \n",
        "history=tpu_model.fit_generator(\n",
        "                           train_generator(),\n",
        "                           steps_per_epoch = 150,\n",
        "                           validation_data = test_generator(),\n",
        "                           validation_steps = 30,\n",
        "                           epochs=15           \n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "btm9bCkXMg-H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Save weights on Gdrive. Ajust destination File as desired"
      ]
    },
    {
      "metadata": {
        "id": "E1jeiuwGMUpO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tpu_model.save(os.path.join(folder(weights_folder),'last_checkpoint_TPU.hdf5'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ln_n95miMkUF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "copy(os.path.join(folder(weights_folder),'last_checkpoint_TPU.hdf5'),os.path.join('/content/gdrive/My Drive/TPU',name+'.hdf5'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZfVj9RxwNSx9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Chart Accuracy and Loss**"
      ]
    },
    {
      "metadata": {
        "id": "ta8svhOnN0s2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "loss = history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "acc=history.history['dice_coef']\n",
        "\n",
        "epochs = range(1, len(loss) + 1)\n",
        "\n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "# bo is blue dots\n",
        "plt.plot(epochs, val_loss, 'bo', label='Test loss')\n",
        "# b is for \"solid blue line\"\n",
        "plt.title('Training and test loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e7Edl_4DOET0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "loss = history.history['loss']\n",
        "acc=history.history['dice_coef']\n",
        "val_acc=history.history['val_dice_coef']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'b', label='Dice')\n",
        "# bo is blue dots\n",
        "plt.plot(epochs, val_acc, 'bo', label='Test dice')\n",
        "# b is for \"solid blue line\"\n",
        "plt.title('Training and test Dice')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Acc')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KqzTU_uoOICD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Visual Check\n",
        "Let's start by finding the best and worst predictions and plot them"
      ]
    },
    {
      "metadata": {
        "id": "hglC8YtD0Qd3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_s=int(X_testc.shape[0])\n",
        "test_s=test_s-test_s%8\n",
        "test_s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MTsLU6aHfH6r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "smooth=1e-07\n",
        "\n",
        "def np_dice_coef(y_true, y_pred):\n",
        "    y_true_f = y_true.flatten()\n",
        "    y_pred_f = y_pred.flatten()\n",
        "    intersection = np.sum(y_true_f * y_pred_f)\n",
        "    return ( (2. * intersection + smooth) / \n",
        "             (np.sum(y_true_f) + np.sum(y_pred_f) + smooth) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_VDf5M6OONHg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Acquiring scores for the validation set:"
      ]
    },
    {
      "metadata": {
        "id": "C-MAss7tr_-h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "pred_dice=np.empty((test_s), dtype=np.float32)\n",
        "\n",
        "\n",
        "\n",
        "sess = K.get_session()\n",
        "\n",
        "batch_X = X_testc[0:test_s]\n",
        "batch_y = Y_testc[0:test_s]\n",
        "print (batch_X.shape)\n",
        "    \n",
        "predv = (tpu_model.predict(batch_X)[...,0]>0.5).astype(np.float32)\n",
        "corrv= (batch_y)[ ..., 0].astype(np.float32)\n",
        "\n",
        "\n",
        "for i in tqdm_notebook(range(predv.shape[0])):\n",
        "    #print('image #{}'.format(i))\n",
        "    img = X_test[i]\n",
        "    \n",
        "    pred = predv[i]\n",
        "    corr = corrv[i]\n",
        "    cur_dice = np_dice_coef(pred, corr)\n",
        "    #print(cur_dice)\n",
        "    pred_dice[i]=(cur_dice)\n",
        "\n",
        "    \n",
        "    \n",
        "d_worst=np.amin(pred_dice)\n",
        "d_best=np.amax(pred_dice)\n",
        "d_mean=np.mean(pred_dice)\n",
        "d_std=np.std(pred_dice)\n",
        "print(\"Dice mean=\",d_mean, \" Std=\",d_std, \" best=\",d_best,\" worst=\",d_worst)\n",
        "\n",
        "i_best=np.argmax(pred_dice)\n",
        "i_worst=np.argmin(pred_dice)\n",
        "\n",
        "for i in [i_best,i_worst]:\n",
        "    print('image #{}'.format(i))\n",
        "    img = X_test[i]\n",
        "    pred = predv[i]\n",
        "    corr = corrv[i]\n",
        "    \n",
        "    print(pred_dice[i])\n",
        "    fig = plt.figure(figsize=(9, 4))\n",
        "    ax = fig.add_subplot(1, 3, 1)\n",
        "    ax.imshow(pred, cmap=plt.cm.Greys_r)\n",
        "    ax.set_title('Predicted')\n",
        "    ax = fig.add_subplot(1, 3, 2)\n",
        "    ax.imshow(corr, cmap=plt.cm.Greys_r)\n",
        "    ax.set_title('Correct')\n",
        "    ax = fig.add_subplot(1, 3, 3)\n",
        "    #ax.imshow(img)\n",
        "    ax.imshow(img)\n",
        "    ax.set_title('Image')\n",
        "    plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8MTOHFOcs0Zv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now lets find the Radii ratio parameter (among other info)"
      ]
    },
    {
      "metadata": {
        "id": "E4tnfxZtRDRP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "batch_X = X_testc[0:test_s]\n",
        "batch_y = Y_testc[0:test_s]\n",
        "print (batch_X.shape)\n",
        "    \n",
        "predv = (tpu_model.predict(batch_X)[...,0]>0.5).astype(np.float32)\n",
        "corrv= (batch_y)[ ..., 0].astype(np.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TMie7BywRofc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cup_rr= np.empty((test_s), dtype=np.float32)\n",
        "cup_dc= np.empty((test_s), dtype=np.float32)\n",
        "cup_ac= np.empty((test_s), dtype=np.float32)\n",
        "cup_ap= np.empty((test_s), dtype=np.float32)\n",
        "\n",
        "\n",
        "predc = predv[0, ...].copy()\n",
        "corrc= corrv[0, ...].copy()\n",
        "print (predc.shape)\n",
        "\n",
        "for i in tqdm_notebook(range(test_s), leave=True):\n",
        "    \n",
        "    predc = predv[i]\n",
        "    corrc = corrv[i]\n",
        "    \n",
        "    label_pc = skimage.measure.label(predc, connectivity=predc.ndim)\n",
        "    props_pc = skimage.measure.regionprops(label_pc)\n",
        "    \n",
        "    label_cc = skimage.measure.label(corrc, connectivity=corrc.ndim)\n",
        "    props_cc = skimage.measure.regionprops(label_cc)\n",
        "    \n",
        "    sz=len(props_pc)\n",
        "    if(sz)!=0:\n",
        "      areap=[props_pc[i].area for i in range(sz)]\n",
        "      #print(sz,areap)\n",
        "      k=np.argmax(areap)\n",
        "    \n",
        "      xcp = props_pc[k].centroid[0] #x center\n",
        "      ycp = props_pc[k].centroid[1] #y_center\n",
        "      ap = props_pc[k].area\n",
        "    else:\n",
        "      xpc=0\n",
        "      ypc=0\n",
        "      ac=0\n",
        "    \n",
        "    xcc = props_cc[0].centroid[0] #x center\n",
        "    ycc = props_cc[0].centroid[1] #y_center\n",
        "    ac = props_cc[0].area\n",
        "\n",
        "\n",
        "    \n",
        "    if (ap>ac):\n",
        "      ar=ac/ap\n",
        "    else:\n",
        "      ar=ap/ac\n",
        "      \n",
        "    dist=math.sqrt((xcp-xcc)*(xcp-xcc)+(ycp-ycc)*(ycp-ycc))\n",
        "    cup_rr[i]=math.sqrt(ar)\n",
        "    cup_dc[i]=dist\n",
        "    cup_ac[i]=ac\n",
        "    cup_ap[i]=ap"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t97oQ7wAqclb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "print('best radii ratio= {:0.2f}, worst radii ratio= {:0.2f}, worst center distance= {:0.2f}, best center distance= {:0.2f}'.format(np.amax(cup_rr),np.amin(cup_rr),np.amax(cup_dc),np.amin(cup_dc)))\n",
        "bt90=cup_rr>.9\n",
        "print('Percentage of images with less than 10% radius error ={:0.2f}'.format(sum(bt90)/test_s))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q-40eOaPtE3p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's take a look at the predicted OD or OC shapes."
      ]
    },
    {
      "metadata": {
        "id": "pVYYcu5UthfY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(predv.shape)\n",
        "for i in range(predv.shape[0]):\n",
        "    fig = plt.figure(figsize=(9, 4))\n",
        "    ax = fig.add_subplot(1, 3, 1)\n",
        "    ax.imshow(predv[i], cmap=plt.cm.Greys_r)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CZ52cTNKtRzE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The next cell is just to Stop the code "
      ]
    },
    {
      "metadata": {
        "id": "Ra3BdVXn-P4i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "breakpoint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NKFF0vg2tYsD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Use this to reload the model. Before dooing this it is necesary to  run until the training step.\n",
        "After loading the weights. Recompile the TPU model."
      ]
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "8DwVY5n8wswB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "copy('/content/gdrive/My Drive/TPU/'+name+'.hdf5','/content/last_checkpoint.hdf5')\n",
        "tpu_model.load_weights('/content/last_checkpoint.hdf5','/content/last_checkpoint.hdf5')\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}